<?xml version="1.0" encoding="UTF-8" ?><rss version="2.0"><channel><title>Help Wanted</title><description>Help Wanted Issues</description><link>https://robotonomi.github.io/workspace/feed.xml</link><item>	<title>Add Carthage compatibility badge to the README</title>	<link>https://github.com/github/Archimedes/issues/38</link>	<description><![CDATA[Using  <a href="https://github.com/Carthage/Carthage/blob/7a0153cc164e301c46527f6e20c886728a0dc218/README.md#declare-your-compatibility">these instructions</a> 

.<br/>" ]]></description></item><item>	<title>license yaml format issue</title>	<link>https://github.com/github/choosealicense.com/issues/758</link>	<description><![CDATA[The `using` part of the license.txt looks weird to me. It's an array of single-element map like this<br/>```yaml<br/>using:<br/>  - youtube-dl: https://github.com/rg3/youtube-dl/blob/master/LICENSE<br/>  - kakoune: https://github.com/mawww/kakoune/blob/master/UNLICENSE<br/>  - RDF.rb: https://github.com/ruby-rdf/rdf/blob/master/UNLICENSE<br/>```<br/>why not just use a single map like this<br/>```yaml<br/>using:<br/>  youtube-dl: https://github.com/rg3/youtube-dl/blob/master/LICENSE<br/>  kakoune: https://github.com/mawww/kakoune/blob/master/UNLICENSE<br/>  RDF.rb: https://github.com/ruby-rdf/rdf/blob/master/UNLICENSE<br/>```<br/>or an array of structered map<br/>```yaml<br/>using:<br/>  - name: youtube-dl<br/>    url: https://github.com/rg3/youtube-dl/blob/master/LICENSE<br/>  - name: kakoune<br/>    url: https://github.com/mawww/kakoune/blob/master/UNLICENSE<br/>  - name: RDF.rb<br/>    url: https://github.com/ruby-rdf/rdf/blob/master/UNLICENSE<br/>```<br/>It makes the deserialise code boilerplate, for e.g in Rust I have to declare this field like <br/>```Rust<br/>using: Option<Vec<HashMap<String, String>>>,<br/>```<br/>When using this `using` field, I have to iterate the vector, during which I have to iterate the single-element map!<br/>In other formats, it would be<br/>```Rust<br/>using: Option<HashMap<String, String>>,<br/>```<br/>or<br/>```Rust<br/>using: Option<Vec<SomeStruct>>,<br/>```" ]]></description></item><item>	<title>Improved user experience: choosealicense.com/appendix</title>	<link>https://github.com/github/choosealicense.com/issues/703</link>	<description><![CDATA[First, I really love this page:  <a href="https://choosealicense.com/appendix">https://choosealicense.com/appendix</a> 

<br/><br/>One way it can be improved is to include some \"yes/no/undefined\" check-boxes along the top of the table.<br/>When you eg: check the box above: \"Same License\" it brings all \"same licenses\" to the top &amp; grays out all other licenses.<br/>* If you check several boxes, only those licenses with ALL checked conditions are highlighted.<br/>* Below those (partially grayed out, or something)
 are licenses that partially match the check-boxes (in decreasing number of matches)
.<br/>* And below that too is the remaining licenses, totally grayed out.<br/><br/>That would make this page awesome to use.<br/>Thanks &amp; hope this helps." ]]></description></item><item>	<title>Test that license texts match SPDX plain license texts</title>	<link>https://github.com/github/choosealicense.com/issues/636</link>	<description><![CDATA[We should have a test that each license text in `_licenses` is the same as the plain text license in the SPDX collection to automate the requirement described at https://github.com/github/choosealicense.com/blob/gh-pages/CONTRIBUTING.md#adding-a-license<br/><br/>> The text of the license should match the corresponding text found in  <a href="https://github.com/spdx/license-list-data/blob/master/text/">spdx/license-list-data</a> 

. If there are errors there, please fix them in  <a href="https://github.com/spdx/license-list-XML">spdx/license-list-XML</a> 

 (from which the plain text version is generated)
 so as to minimize license text variation and make it easier for choosealicense.com to eventually consume license texts directly from SPDX.<br/><br/>The test could clone spdx/license-list-data and compare each license we have cataloged in this project. Many existing licenses would probably have to be marked as expected failures due to bugs in SPDX output and discrepancies in how this project has cataloged some licenses. But we should address upfront for any new license cataloged here, and continue to chip away at the existing inconsistencies." ]]></description></item><item>	<title>Annotating license texts with license rules</title>	<link>https://github.com/github/choosealicense.com/issues/441</link>	<description><![CDATA[ <a href="https://github.com/github/choosealicense.com/pull/320#issuecomment-230746990">Comment/question today</a> 

 about whether EUPL-1.1 is accurately described reminded me to file this enhancement idea.<br/><br/>For each license, license rules could be annotated with ranges of text in the license pertinent to the rule. Highlighting of ranges could be turned on/off on individual license pages by selecting in the license rules (permissions/conditions/limitations)
 table. Very crude mockup taking a very simple case (the one condition of MIT)
.<br/><br/>! <a href="https://cloud.githubusercontent.com/assets/40415/16633043/25735510-437c-11e6-84f8-1e504d48f345.png">mit-highlight-condition</a> 

<br/><br/>Obviously this is not a big help for MIT, but for longer licenses, it can be tricky to figure out what bits of the license are pertinent for a particular rule, at least if you only want to read once, which is more already than I suspect most people do.<br/><br/>Such annotations _might_ be very helpful to \"demystify\" licenses, and creating them might be good QA for choosealicense.com license descriptions.<br/><br/>Probably the simplest way to to annotate would be to have one or more full text extracts for each license for each rule, though there are other ways to do it, inline or  <a href="https://github.com/hypothesis/h/wiki/robust-anchors">out of band</a> 

.<br/><br/>Very low priority, may even be a bad idea, just recording it for now.<br/>" ]]></description></item><item>	<title>Add Free Art License</title>	<link>https://github.com/github/choosealicense.com/issues/314</link>	<description><![CDATA[ <a href="http://artlibre.org/licence/lal/en/">Free Art License 1.3</a> 

<br/>" ]]></description></item><item>	<title>I18N</title>	<link>https://github.com/github/choosealicense.com/issues/68</link>	<description><![CDATA[Would love to see about baking in I18N support to choosealicense.com proper. See #67 and #62<br/><br/>We already have the bulk of the strings in a single file (`_config.yml`)
, so it should just be a matter of abstracting out some of our variables, as far as I can tell.<br/><br/>Would love to take this on starting in August if there's interest. Would be a great exercise to set a standard for Jekyll L10N, and can iterate on some of the lessons learned form https://github.com/CMSgov/healthcare.gov.<br/><br/>@parkr any interest?<br/>@dhcole any insight / words of wisdom?<br/>" ]]></description></item><item>	<title>Support for locally present bundles</title>	<link>https://github.com/github/codeql-action/issues/154</link>	<description><![CDATA[I would like to run code-scanning with a custom code-scanning bundle<br/>that already is present on my local disk.  I can currently do that by<br/>making the following hack:<br/><br/>### 1 Install bundle in tool cache:<br/><br/>Use `toolCache.cacheDir` to install the bundle with a specially crafted ID:<br/><br/>```js<br/>tc.cacheDir(localBundlePath, 'CodeQL', \"0.0.0-XXX-DUMMY-BUNDLE-ID\")
;<br/>```<br/><br/>### 2 Convince codeql to look in the tool cache:<br/><br/>The codeql action is then invoked with a dummy URL that will make codeql.ts lookup the bundle with the specially crafted ID:<br/><br/>```yaml<br/>        ...<br/>        tools: dummy://codeql-bundle-XXX-DUMMY-BUNDLE-ID/dummy<br/>        ...<br/>```<br/><br/>---<br/><br/>This works, but I would like a more reliable solution.  I am not sure<br/>what the best approach is for supporting my use case, but I am happy<br/>to look into implementing a suggestion.<br/>" ]]></description></item><item>	<title>TODO: Configure caching for fast building on travisci</title>	<link>https://github.com/github/government.github.com/issues/750</link>	<description><![CDATA[Description and details here: https://github.com/gjtorikian/html-proofer#configuring-caching and https://github.com/gjtorikian/html-proofer#caching-with-travis" ]]></description></item><item>	<title>Alphabetize, other chores should run monthly, open new PRs automatically</title>	<link>https://github.com/github/government.github.com/issues/601</link>	<description><![CDATA[Currently, the alphabetize script (https://github.com/github/government.github.com/blob/gh-pages/script/alphabetize)
  is run manually to clean up the ordering of Organizations in the various data files. (Example: https://github.com/github/government.github.com/pull/582)
. A couple problems with this:<br/><br/>1. Why do work that a robot ðŸ¤– can do?<br/>2. Since this repo is widely maintained, it's impossible to guarantee that these changes won't create pretty annoying conflicts for other PRs. <br/><br/>Getting these to a near automated fashion would be really cool.<br/><br/>I'd held off merging a bunch of  <a href="https://github.com/github/government.github.com/pulls?utf8=%E2%9C%93&amp;q=is%3Apr%20is%3Aopen%20updated%3A%3E2017-07-01">open PRs</a> 

 in hopes that I'd get time to work on a solution for this, but alas I have not. So, I figure I'll crowd source this to see if anyone has any ideas or fancy the execution.<br/><br/>## Note<br/>I'd love to use  <a href="https://probot.github.io">probot</a> 

 as the framework for these operations (it's what it was made for)
, but it's currently a node app and is expecting j/s scripts. Since I try to do as little with YAML as possible ðŸ˜‰ , this task was never exciting enough to get my attention for very long, and why it floundered. It should be pretty easy as `js-yaml` and basic JS functions should map pretty cleanly.<br/><br/>By opening this issue, this will be a reminder to me to eventually get to it too, so no pressure." ]]></description></item><item>	<title>Dockerfile support</title>	<link>https://github.com/github/licensed/issues/272</link>	<description><![CDATA[Would be great if `licensed` supported analyzing `Dockerfile`s and what is installed there to track all dependencies of a project!" ]]></description></item><item>	<title>XML report for CI</title>	<link>https://github.com/github/licensed/issues/52</link>	<description><![CDATA[Hi,<br/><br/>I'm integrating licensed for a poc in our Jenkins pipeline. It could be great to get a report of all licenses checks in an XML formatted file; so we can process it using Jenkins plugins. For now, I have to analyse the `XXX dependencies checked, XXX warnings found.` string formatted output of `licensed status` command.<br/><br/>We can consider **licensed results** as **tests results**.<br/>* If all licenses check passed; then the overall test is **passed**.<br/>* If one license is found as unknown, or not matching any of allowed, ignored or reviewed configs; then the check/test **failed**.<br/><br/>Standards test output formats such as junit, nunit, mstest, google-test, etc. would be great cos already known by many CI tools. Junit is probably the most used one.<br/><br/>Organizing tests in \"groups\" matching the package type (npm, pip, go, etc.)
 and license type (mit, gpl...)
 would also allows to \"count\" the type of licenses found... providing some kind of statistics ^<br/><br/>Example of output in Jenkins test plugin results, processing the XML file could be:<br/>```<br/>Package                  Fail Skip Pass Total<br/>- total                     0    0   69    69<br/>- npm                       0    0   53    53<br/>  - mit                     0    0   45    45<br/>    - package1              0    0    1     1<br/>    - package 2             ...<br/>    - ...<br/>  - apache-2.0                              3<br/>    - package46<br/>    - ...<br/>  - bsd-3-clause                            1 <br/>    - package49<br/>  - isc                                     1<br/>    - package50<br/>  - unknown                                 3<br/>    - package51             1    0    0     1<br/>    - ...<br/>- go                                       16<br/>  - mit                                    14<br/>    - ...<br/>  - isc                                     1<br/>    - ...<br/>  - unknown                                 1<br/>    - packagexx             1    0    0     1<br/>    - ...<br/>```<br/>I did not fill the array; but you've got the point ;-)
<br/><br/>Regards,<br/><br/>Chris" ]]></description></item><item>	<title>Question about tags</title>	<link>https://github.com/github/octocatalog-diff/issues/209</link>	<description><![CDATA[Is there any way to have octocatalog-diff do the opposite of --ignore-tags?  I'd like to be able to specify one or more tags and have octocatalog-diff only compare resources containing those tags?  This would help predict the behavior of running puppet with those tags." ]]></description></item><item>	<title>Consider not using LCS by default or allow switching it off</title>	<link>https://github.com/github/octocatalog-diff/issues/207</link>	<description><![CDATA[Hi,<br/><br/> <a href="https://github.com/github/octocatalog-diff/blob/master/lib/octocatalog-diff/catalog-diff/differ.rb#L525">Hashdiff</a> 

 uses  <a href="https://github.com/liufengyun/hashdiff#use_lcs">LCS by default</a> 

 when comparing arrays. This algorithm produces a friendlier and easier to read diff for humans, but at  <a href="https://github.com/liufengyun/hashdiff/issues/49">high cost</a> 

 O(n<sup>2</sup>)
.<br/><br/>Would you consider a patch to either disable LCS or perhaps to allow switching it off via the command line? I'd happy to prepare it.<br/><br/>Thanks." ]]></description></item><item>	<title>Turn parallel_tests back on for CI</title>	<link>https://github.com/github/octocatalog-diff/issues/164</link>	<description><![CDATA[Recently the CI for octocatalog-diff has been pretty flaky due to random tests getting killed. From travis CI documents, I concluded that the individual tests may be exhausting resources of the container, and as such in https://github.com/github/octocatalog-diff/pull/161 I disabled the parallel_tests gem for CI. Since then, no problems. :crossed_fingers: But, unfortunately the CI build time per ruby version increased by about 5 minutes (20 to 25)
 as a result of this change.<br/><br/>I'm entering this issue to keep track turning this back on. Things that would probably need to be done here would be to evaluate whether the tests can be effectively parallelized (perhaps the spec tests)
 or if the number of simultaneous processes can be reduced to keep from bumping up against any limits that exist.<br/><br/>Right now nobody is actively working on this (there are higher priorities)
. However if test parallelization is something that interests you and you'd like to have a go at making the CI faster, please comment in the issue! ðŸ˜¸ " ]]></description></item><item>	<title>How to use a different puppet configuration (e.g. strict_variables)
</title>	<link>https://github.com/github/octocatalog-diff/issues/158</link>	<description><![CDATA[Hey, I have set `strict_variables` (https://puppet.com/docs/puppet/4.10/configuration.html#strictvariables)
 to true on the puppetmaster. Now I also want this setting to be there for the octocatalog-diff run. Unfortunately I couldn't figure out how I could do that. The only think I could think of would be to add a bootstrapping script which creates a puppet.conf with that setting. But this doesn't feel right :)
<br/><br/>Does someone has an idea how I could do that?" ]]></description></item><item>	<title>Investigate semantic-rust macro tests</title>	<link>https://github.com/github/semantic/issues/553</link>	<description><![CDATA[@p-alik has graciously added the `semantic-rust` package but we've had to exclude some macro corpus tests due to parsing issues.<br/><br/>See https://github.com/github/semantic/pull/551 for details." ]]></description></item><item>	<title>R support</title>	<link>https://github.com/github/semantic/issues/382</link>	<description><![CDATA[R is a  <a href="https://stackoverflow.blog/2017/10/10/impressive-growth-r/">widely used</a> 

, growing language often used in Data Science and Statistics.<br/><br/>While it does not have a published formal specification, there is a  <a href="https://cran.r-project.org/doc/manuals/r-release/R-lang.pdf">draft specification</a> 

 that describes lexing and parsing the language.<br/><br/>In the most  <a href="https://github.com/wch/r-source">widely used implementation</a> 

 the parsing is done with a bison parser defined in  <a href="https://github.com/wch/r-source/blob/ff1bca2f21aba271d428474f00494eece5c36dd3/src/main/gram.y">gram.y</a> 

.<br/><br/>The lexing rules for R are somewhat complex, but the parsing is relatively straightforward, as generally everything is an expression.<br/><br/>It would very beneficial to the R community to have support for R in semantic!" ]]></description></item><item>	<title>Don't connect to kext when invoked with CLI args</title>	<link>https://github.com/github/SoftU2F/issues/39</link>	<description><![CDATA[We try to connect to the kext when the app starts ( <a href="https://github.com/github/SoftU2F/blob/45825a5bd6e6bad7ae9bd681c8584cbcb6e7fb7b/SoftU2FTool/U2FHID.swift#L24">code</a> 

)
. This also happens when the app is launched from the command line (Eg. for deleting/listing registrations)
. If the app is already running in the background we'll get an error because the kext only allows one connection. This error is surfaced to the user, which is confusing. We should not connect to the kext unless we need to." ]]></description></item><item>	<title>Fix Tap reporting tests</title>	<link>https://github.com/github/super-linter/issues/453</link>	<description><![CDATA[We have several `.tap` that are ignored and either need to be:<br/>- Fixed<br/>- Removed<br/><br/>This would greatly help if someone could take a look :)
<br/>" ]]></description></item><item>	<title>Scala Support</title>	<link>https://github.com/github/super-linter/issues/392</link>	<description><![CDATA[Scala linter support.<br/><br/>Choices are<br/>-  <a href="https://github.com/scalacenter/scalafix">scalafix</a> 

<br/>-  <a href="https://github.com/scalameta/scalafmt">scalafmt</a> 

<br/>-  <a href="https://github.com/scalastyle/scalastyle">scalastyle</a> 

<br/>-  <a href="https://github.com/wartremover/wartremover">wartremover</a> 

" ]]></description></item><item>	<title>Exclude folder from lint operations</title>	<link>https://github.com/github/super-linter/issues/374</link>	<description><![CDATA[Hi<br/><br/>is it possible to somehow exclude entire directory from linting?<br/>during my workflow except checking out the current repository i also checking out another repository which includes personal github actions.<br/>i want to exclude this directory from super linter operation as i dont want it to be analyzed for all repos.<br/><br/>any way to achieve this?<br/>10x!" ]]></description></item><item>	<title>Fix GO linting</title>	<link>https://github.com/github/super-linter/pull/370</link>	<description><![CDATA[As pointed out in #143, running super-linter on Golang code breaks as soon as packages are split in more than one files, which can happen even with moderately simple projects. The idea in this PR is to fix this issue by running `golangci-lint` on whole directories instead of singular files, when `VALIDATE_ALL_CODEBASE == false` and recursively on the whole repo otherwise.<br/><br/>Feedback is greatly appreciated on all points, but especially on the following:<br/><br/>- The array of go files to analyze will potentially contain multiple repeated entries. To get rid of them I am using the following commnad: `  mapfile -t FILE_ARRAY_GO < <(printf '%s\<br/>' \"${FILE_ARRAY_GO[@]}\" | sort -u)
` Any suggestion on better approaches from more experienced bash developers is highly appreciated.<br/>- With this solution, the number of errors reported by SuperLinter will be always heavily underestimated. If running against all codebase, it will at most be 1; otherwise, it will be at most 1 for every directory analysed. Please note that, however, at the moment the number of errors is already not exactly the number of errors found by the linter but only the number of files with one or more errors (example  <a href="https://github.com/bznein/AoC2019-Go/runs/834384999?check_suite_focus=true">here</a> 

 when the number of errors is equal to 1 while there are 3 errors in a single file)
<br/><br/>A Docker image built from the code in this PR is available at https://hub.docker.com/r/bznein/superlinter" ]]></description></item><item>	<title>spawning eslint instance for each file</title>	<link>https://github.com/github/super-linter/issues/288</link>	<description><![CDATA[**Describe the bug**<br/><br/>it seems the default setup is spawning an individual eslint command run for each file in the repo!<br/><br/>**To Reproduce**<br/>Steps to reproduce the behavior:<br/>1. add `super-linter` using docker:<br/>  ```<br/>      steps:<br/>      - uses: actions/checkout@v2<br/>      - uses: docker://github/super-linter:v2.0.0<br/>  ```<br/>2. run <br/>3. lint run duration is excessively high even for small repos, due to spawning per file.<br/><br/>**Expected behavior**<br/><br/>`eslint` should run on the entire folder without individual spawn event<br/><br/>**Screenshots**<br/><br/>! <a href="https://user-images.githubusercontent.com/183195/85863262-ec8c1b00-b790-11ea-806f-afb8e0856c1d.png">image</a> 

<br/><br/>**Additional Context**<br/><br/>This repo has less than 20 js files in total => took 3 m 18 s to run <br/><br/>! <a href="https://user-images.githubusercontent.com/183195/85863625-6de3ad80-b791-11ea-9309-481203007b25.png">image</a> 

<br/>" ]]></description></item><item>	<title>Lint files in specific directories only</title>	<link>https://github.com/github/super-linter/issues/225</link>	<description><![CDATA[**Is your feature request related to a problem? Please describe.**<br/>I would like to be able to lint my `src` directory only, not `test` or any other directory.<br/><br/>**Describe the solution you'd like**<br/>This could be an option in ENV:<br/><br/>```yaml<br/>env:<br/>  LINT_FILES: [folder, folder/subfolder/*.js]<br/>```<br/><br/>As you can see in the example, this could be further improved by accepting wild cards.<br/><br/>**Describe alternatives you've considered**<br/>I haven't found any alternative so far.<br/><br/>Thank you.<br/>" ]]></description></item><item>	<title>C# Support with ResharperCommandLine Tools</title>	<link>https://github.com/github/super-linter/pull/189</link>	<description><![CDATA[I added resharper command line tools to the dockerfile and updated the linter to add checking for csharp but I'm unsure of how to test this?" ]]></description></item><item>	<title>Ruby: Switch from RuboCop to StandardRB</title>	<link>https://github.com/github/super-linter/issues/188</link>	<description><![CDATA[The beauty of Ruby Standard Style is that it's simple. No one wants to maintain multiple hundred-line style configuration files for every module/project they work on. RuboCops defaults are not that complete.<br/><br/>Under the hood standard uses RuboCop but with saner community defaults that are not customized by GitHub only.<br/>In my opinion using standard better match the philosophy of this project.<br/><br/>https://github.com/testdouble/standard<br/>" ]]></description></item><item>	<title>Support the GitHub Checks Run UI</title>	<link>https://github.com/github/super-linter/issues/151</link>	<description><![CDATA[**Is your feature request related to a problem? Please describe.**<br/>After the super-linters runs, you have to go to the workflow logs, and then the step, and look at the logs, to see the errors that were found. This is not ideal and error-prone. <br/><br/>**Describe the solution you'd like**<br/>A better approach would be to use the  <a href="https://developer.github.com/v3/checks/runs/#create-a-check-run">Checks Run UI</a> 

 to report the errors directly into the PR/code lines, to better visibility.<br/><br/>**Describe alternatives you've considered**<br/>Other linters already do this like https://github.com/andrewmcodes/rubocop-linter-action and https://github.com/devmasx/brakeman-linter-action<br/><br/>**Additional context**<br/>I think this is a really big feature, but it will also improve a lot the super-linter, and we could leverage how others already do it.<br/><br/>" ]]></description></item><item>	<title>depends option test regression</title>	<link>https://github.com/ubuntu/ubuntu-make/issues/613</link>	<description><![CDATA[There's a branch with the --depends option, that lists the needed (or installed)
 dependencies.<br/>This introduced a regression in the tests, so it will not be merged until it's fixed.<br/>If someone wants to have a go at finding the issue the branch is https://github.com/ubuntu/ubuntu-make/tree/list_depends<br/>Closes #610 " ]]></description></item><item>	<title>No CLI parameter to specify installation path directly from command line (unable to use ubuntu-make in chef)
</title>	<link>https://github.com/ubuntu/ubuntu-make/issues/403</link>	<description><![CDATA[Does anyone have a reliable workaround to automatically accept the default installation path when prompted? Specifically for ide eclipse-jee.<br/><br/>I tried using \"yes\", but then it doesn't set the default installation path at all and installs it into the void. \"Expect\" also gets confused, what I need is to set the installation path directly:<br/><br/>umake ide eclipse-jee --path \"/home/vagrant/.local/share/umake/ide/eclipse-jee\"<br/><br/>This would make umake useful in automatic configuration management tools (e.g. chef)
.<br/>" ]]></description></item><item>	<title>Add Racket support</title>	<link>https://github.com/ubuntu/ubuntu-make/issues/200</link>	<description><![CDATA[It would be nice if support for Racket and DrRacket would be added. Please consider it, thx :smile: <br/>http://racket-lang.org/<br/>" ]]></description></item><item>	<title>Umake should safely remove all the packages it installed</title>	<link>https://github.com/ubuntu/ubuntu-make/issues/192</link>	<description><![CDATA[When I use the \"-- remove\" argument it does not remove all the packages that were installed. It would be good if \"umake -r\" also removes the redundant packages that it installed.<br/>" ]]></description></item><item>	<title>Add: Lazarus IDE and FPC</title>	<link>https://github.com/ubuntu/ubuntu-make/issues/149</link>	<description><![CDATA[Please, add this great RAD solution. It can compile to different targets and architectures.<br/>The version provided in the USC it is old and conflicts with new versions.<br/>http://www.lazarus-ide.org/<br/>" ]]></description></item><item>	<title>Support for Mono and Mono Develop</title>	<link>https://github.com/ubuntu/ubuntu-make/issues/94</link>	<description><![CDATA[It would be nice if support for Mono and Mono Develop would be added. Please consider it :)
<br/>" ]]></description></item><item>	<title>Add Perl support</title>	<link>https://github.com/ubuntu/ubuntu-make/issues/85</link>	<description><![CDATA[Please also add Perl support via perlbrew/plenv and Padre as IDE.<br/>" ]]></description></item></channel></rss>
